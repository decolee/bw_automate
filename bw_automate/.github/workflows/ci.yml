name: BW_AUTOMATE CI/CD Pipeline

on:
  push:
    branches: [ master, develop ]
  pull_request:
    branches: [ master ]
  schedule:
    - cron: '0 2 * * 1'  # Weekly on Monday at 2 AM

env:
  PYTHON_VERSION: '3.11'
  POSTGRES_VERSION: '15'

jobs:
  # Code Quality Checks
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black mypy pytest pytest-cov
        pip install -r requirements.txt
        
    - name: Lint with flake8
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=100 --statistics
        
    - name: Format check with black
      run: black --check --diff .
      
    - name: Type check with mypy
      run: mypy . --ignore-missing-imports --no-strict-optional
      continue-on-error: true

  # Security Scanning
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit
        pip install -r requirements.txt
        
    - name: Run safety check
      run: safety check --json --output safety-report.json
      continue-on-error: true
      
    - name: Run bandit security scan
      run: bandit -r . -f json -o bandit-report.json
      continue-on-error: true
      
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          safety-report.json
          bandit-report.json

  # Unit and Integration Tests
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: bw_test_password
          POSTGRES_USER: bw_test_user
          POSTGRES_DB: bw_test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-xdist
        pip install -r requirements.txt
        
    - name: Setup test database
      run: |
        export PGPASSWORD=bw_test_password
        psql -h localhost -U bw_test_user -d bw_test_db -c "
          CREATE TABLE IF NOT EXISTS test_users (id SERIAL PRIMARY KEY, name VARCHAR(100));
          CREATE TABLE IF NOT EXISTS test_orders (id SERIAL PRIMARY KEY, user_id INTEGER);
          INSERT INTO test_users (name) VALUES ('Test User 1'), ('Test User 2');
        "
        
    - name: Run comprehensive test suite
      run: python3 COMPREHENSIVE_TEST_SUITE.py
      env:
        POSTGRES_TEST_URL: postgresql://bw_test_user:bw_test_password@localhost:5432/bw_test_db
        
    - name: Run unit tests with pytest
      run: pytest -v --cov=. --cov-report=xml --cov-report=html
      continue-on-error: true
      
    - name: Test CLI integration
      run: |
        python3 BW_UNIFIED_CLI.py info
        python3 BW_UNIFIED_CLI.py analyze . --type postgresql --output test_results
        
    - name: Test Airflow integration
      run: |
        python3 AIRFLOW_INTEGRATION_CLI.py analyze . --mode basic --output airflow_test_results
        
    - name: Upload test results
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: |
          comprehensive_test_results.json
          test_results/
          airflow_test_results/
          htmlcov/
          
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false

  # Performance Testing
  performance:
    name: Performance Tests
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install memory-profiler psutil
        
    - name: Run performance benchmarks
      run: |
        echo "=== Performance Benchmarks ===" > performance-report.txt
        echo "Date: $(date)" >> performance-report.txt
        echo "" >> performance-report.txt
        
        # Benchmark PostgreSQL analysis
        echo "PostgreSQL Analysis Benchmark:" >> performance-report.txt
        time python3 POSTGRESQL_TABLE_MAPPER.py . --output perf_test_postgresql 2>&1 | tee -a performance-report.txt
        
        # Benchmark unified analysis
        echo "Unified Analysis Benchmark:" >> performance-report.txt  
        time python3 BW_UNIFIED_CLI.py analyze . --type all --output perf_test_unified 2>&1 | tee -a performance-report.txt
        
        # Memory usage test
        echo "Memory Usage Test:" >> performance-report.txt
        python3 -c "
        import psutil
        import os
        from POSTGRESQL_TABLE_MAPPER import PostgreSQLTableMapper
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024
        print(f'Initial memory: {initial_memory:.2f} MB')
        
        mapper = PostgreSQLTableMapper()
        result = mapper.analyze_project('.')
        
        final_memory = process.memory_info().rss / 1024 / 1024
        print(f'Final memory: {final_memory:.2f} MB')
        print(f'Memory increase: {final_memory - initial_memory:.2f} MB')
        " 2>&1 | tee -a performance-report.txt
        
    - name: Upload performance report
      uses: actions/upload-artifact@v3
      with:
        name: performance-report
        path: performance-report.txt

  # Docker Build and Test
  docker:
    name: Docker Build & Test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Build Docker image
      run: |
        docker build -t bw-automate:test .
        docker build --target development -t bw-automate:dev .
        
    - name: Test Docker image
      run: |
        docker run --rm bw-automate:test python3 --version
        docker run --rm bw-automate:test python3 BW_UNIFIED_CLI.py info
        
    - name: Test Docker development image
      run: |
        docker run --rm bw-automate:dev python3 COMPREHENSIVE_TEST_SUITE.py
        
    - name: Test Docker Compose
      run: |
        docker-compose -f docker-compose.yml config
        docker-compose -f docker-compose.yml up -d bw-automate
        sleep 10
        docker-compose -f docker-compose.yml exec -T bw-automate python3 BW_UNIFIED_CLI.py info
        docker-compose -f docker-compose.yml down

  # Release and Deployment
  release:
    name: Release
    runs-on: ubuntu-latest
    needs: [quality, security, test, performance, docker]
    if: github.ref == 'refs/heads/master' && github.event_name == 'push'
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
        pip install -r requirements.txt
        
    - name: Build package
      run: python -m build
      
    - name: Check package
      run: twine check dist/*
      
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: dist-packages
        path: dist/
        
    # Uncomment when ready for PyPI publishing
    # - name: Publish to TestPyPI
    #   env:
    #     TWINE_USERNAME: __token__
    #     TWINE_PASSWORD: ${{ secrets.TEST_PYPI_API_TOKEN }}
    #   run: twine upload --repository testpypi dist/*
    #   
    # - name: Publish to PyPI
    #   if: startsWith(github.ref, 'refs/tags/')
    #   env:
    #     TWINE_USERNAME: __token__
    #     TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
    #   run: twine upload dist/*

  # Deployment to staging/production
  deploy:
    name: Deploy
    runs-on: ubuntu-latest
    needs: [release]
    if: github.ref == 'refs/heads/master' && github.event_name == 'push'
    environment: production
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to staging
      run: |
        echo "üöÄ Deploying to staging environment..."
        echo "This would typically deploy to staging servers"
        echo "Current deployment status: Ready for staging"
        
    # Uncomment when production deployment is configured
    # - name: Deploy to production
    #   if: github.ref == 'refs/heads/master'
    #   run: |
    #     echo "üöÄ Deploying to production environment..."
    #     # Add actual deployment commands here

  # Notification
  notify:
    name: Notifications
    runs-on: ubuntu-latest
    needs: [quality, security, test, performance, docker]
    if: always()
    steps:
    - name: Notify on success
      if: ${{ needs.test.result == 'success' }}
      run: |
        echo "‚úÖ All tests passed! Build is healthy."
        echo "Ready for deployment."
        
    - name: Notify on failure
      if: ${{ needs.test.result == 'failure' }}
      run: |
        echo "‚ùå Tests failed! Please check the logs."
        echo "Build needs attention before deployment."