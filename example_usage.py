#!/usr/bin/env python3
"""
BW_AUTOMATE - Exemplo de Uso
============================

Script de exemplo demonstrando como usar o BW_AUTOMATE para an√°lise
de tabelas PostgreSQL em c√≥digos Python do Airflow.

Autor: Assistant Claude
Data: 2025-09-20
"""

import os
import sys
from pathlib import Path

# Adiciona o diret√≥rio do BW_AUTOMATE ao path
bw_automate_dir = Path(__file__).parent
sys.path.insert(0, str(bw_automate_dir))

from run_analysis import BWAutomate


def criar_exemplo_tabelas_xlsx():
    """Cria um arquivo de exemplo com tabelas PostgreSQL"""
    import pandas as pd
    
    # Dados de exemplo
    tabelas_exemplo = {
        'table_name': [
            'usuarios', 'produtos', 'vendas', 'clientes', 'pedidos',
            'estoque', 'categorias', 'fornecedores', 'logs_sistema',
            'auditoria', 'configuracoes', 'relatorios'
        ],
        'schema': [
            'public', 'public', 'public', 'public', 'public',
            'staging', 'public', 'public', 'logs', 'audit',
            'public', 'reports'
        ],
        'tipo': [
            'transacional', 'transacional', 'transacional', 'transacional', 'transacional',
            'staging', 'referencia', 'referencia', 'log', 'auditoria',
            'configuracao', 'relatorio'
        ],
        'descricao': [
            'Cadastro de usu√°rios do sistema',
            'Cat√°logo de produtos',
            'Registro de vendas realizadas',
            'Dados dos clientes',
            'Pedidos dos clientes',
            'Controle de estoque (staging)',
            'Categorias de produtos',
            'Dados dos fornecedores',
            'Logs do sistema',
            'Trilha de auditoria',
            'Configura√ß√µes do sistema',
            'Relat√≥rios gerados'
        ]
    }
    
    df = pd.DataFrame(tabelas_exemplo)
    
    # Salva arquivo Excel de exemplo
    excel_path = "tabelas_exemplo.xlsx"
    df.to_excel(excel_path, index=False)
    
    print(f"‚úÖ Arquivo de exemplo criado: {excel_path}")
    return excel_path


def criar_codigo_python_exemplo():
    """Cria arquivos Python de exemplo com c√≥digo Airflow"""
    
    # Cria diret√≥rio de exemplo
    exemplo_dir = "exemplo_dags"
    os.makedirs(exemplo_dir, exist_ok=True)
    
    # Exemplo 1: DAG de ETL b√°sico
    dag_etl = '''
from airflow import DAG
from airflow.operators.postgres_operator import PostgresOperator
from airflow.operators.python_operator import PythonOperator
import pandas as pd
from datetime import datetime, timedelta

default_args = {
    'owner': 'data_team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}

dag = DAG(
    'etl_vendas_diario',
    default_args=default_args,
    description='ETL di√°rio de vendas',
    schedule_interval='@daily',
    catchup=False
)

# Extrai dados de vendas
extrair_vendas = PostgresOperator(
    task_id='extrair_vendas',
    postgres_conn_id='postgres_default',
    sql="""
        SELECT v.id, v.data_venda, v.valor, c.nome as cliente, p.nome as produto
        FROM vendas v
        JOIN clientes c ON v.cliente_id = c.id
        JOIN produtos p ON v.produto_id = p.id
        WHERE v.data_venda = '{{ ds }}'
    """,
    dag=dag
)

def processar_vendas(**context):
    """Processa dados de vendas"""
    # Conecta com banco
    import psycopg2
    conn = psycopg2.connect("postgresql://user:pass@host/db")
    
    # L√™ dados processados
    df = pd.read_sql("""
        SELECT * FROM staging.vendas_processadas 
        WHERE data_processamento = %s
    """, conn, params=[context['ds']])
    
    # Processa dados
    df['valor_com_desconto'] = df['valor'] * 0.9
    
    # Salva resultado
    df.to_sql('vendas_com_desconto', conn, schema='reports', 
              if_exists='append', index=False)
    
    conn.close()

processar_task = PythonOperator(
    task_id='processar_vendas',
    python_callable=processar_vendas,
    dag=dag
)

# Atualiza estat√≠sticas
atualizar_stats = PostgresOperator(
    task_id='atualizar_estatisticas',
    postgres_conn_id='postgres_default',
    sql="""
        INSERT INTO relatorios.estatisticas_vendas (data, total_vendas, total_desconto)
        SELECT 
            '{{ ds }}' as data,
            SUM(valor) as total_vendas,
            SUM(valor_com_desconto) as total_desconto
        FROM reports.vendas_com_desconto
        WHERE DATE(created_at) = '{{ ds }}'
    """,
    dag=dag
)

extrair_vendas >> processar_task >> atualizar_stats
'''
    
    with open(f"{exemplo_dir}/dag_etl_vendas.py", 'w') as f:
        f.write(dag_etl)
    
    # Exemplo 2: DAG de limpeza de dados
    dag_limpeza = '''
from airflow import DAG
from airflow.operators.postgres_operator import PostgresOperator
import pandas as pd
from datetime import datetime, timedelta

dag = DAG(
    'limpeza_dados_semanal',
    default_args={'owner': 'admin'},
    description='Limpeza semanal de dados',
    schedule_interval='@weekly'
)

# Limpa logs antigos
limpar_logs = PostgresOperator(
    task_id='limpar_logs_sistema',
    postgres_conn_id='postgres_default',
    sql="""
        DELETE FROM logs.logs_sistema 
        WHERE created_at < NOW() - INTERVAL '30 days'
    """,
    dag=dag
)

# Arquiva dados antigos
arquivar_auditoria = PostgresOperator(
    task_id='arquivar_auditoria',
    postgres_conn_id='postgres_default',
    sql="""
        INSERT INTO audit.auditoria_arquivo
        SELECT * FROM audit.auditoria
        WHERE created_at < NOW() - INTERVAL '1 year';
        
        DELETE FROM audit.auditoria
        WHERE created_at < NOW() - INTERVAL '1 year';
    """,
    dag=dag
)

def consolidar_estoque():
    """Consolida dados de estoque"""
    import psycopg2
    
    conn = psycopg2.connect("postgresql://user:pass@host/db")
    
    # L√™ dados de estoque atual
    df_estoque = pd.read_sql("SELECT * FROM estoque", conn)
    
    # L√™ movimenta√ß√µes
    df_movimentacoes = pd.read_sql("""
        SELECT produto_id, SUM(quantidade) as total_movimento
        FROM staging.movimentacoes_estoque
        GROUP BY produto_id
    """, conn)
    
    # Atualiza estoque consolidado
    # ... l√≥gica de consolida√ß√£o ...
    
    # Limpa staging
    cursor = conn.cursor()
    cursor.execute("TRUNCATE TABLE staging.movimentacoes_estoque")
    conn.commit()
    conn.close()

from airflow.operators.python_operator import PythonOperator

consolidar_task = PythonOperator(
    task_id='consolidar_estoque',
    python_callable=consolidar_estoque,
    dag=dag
)

limpar_logs >> arquivar_auditoria >> consolidar_task
'''
    
    with open(f"{exemplo_dir}/dag_limpeza_dados.py", 'w') as f:
        f.write(dag_limpeza)
    
    # Exemplo 3: Script utilit√°rio
    script_util = '''
"""
Utilit√°rios para manipula√ß√£o de dados
"""
import pandas as pd
import psycopg2
from sqlalchemy import create_engine

def conectar_banco():
    """Conecta com banco PostgreSQL"""
    return psycopg2.connect("postgresql://user:pass@host/db")

def extrair_dados_usuarios():
    """Extrai dados de usu√°rios ativos"""
    engine = create_engine("postgresql://user:pass@host/db")
    
    query = """
        SELECT u.id, u.nome, u.email, u.data_cadastro
        FROM public.usuarios u
        WHERE u.ativo = true
        AND u.data_ultimo_acesso > NOW() - INTERVAL '30 days'
    """
    
    return pd.read_sql(query, engine)

def atualizar_configuracoes(nova_config):
    """Atualiza tabela de configura√ß√µes"""
    conn = conectar_banco()
    cursor = conn.cursor()
    
    cursor.execute("""
        UPDATE public.configuracoes 
        SET valor = %s, data_atualizacao = NOW()
        WHERE chave = %s
    """, (nova_config['valor'], nova_config['chave']))
    
    conn.commit()
    conn.close()

def gerar_relatorio_vendas(data_inicio, data_fim):
    """Gera relat√≥rio de vendas por per√≠odo"""
    conn = conectar_banco()
    
    df = pd.read_sql("""
        WITH vendas_periodo AS (
            SELECT 
                DATE(v.data_venda) as data,
                COUNT(*) as total_vendas,
                SUM(v.valor) as receita_total,
                AVG(v.valor) as ticket_medio
            FROM vendas v
            WHERE v.data_venda BETWEEN %s AND %s
            GROUP BY DATE(v.data_venda)
        )
        SELECT * FROM vendas_periodo
        ORDER BY data
    """, conn, params=[data_inicio, data_fim])
    
    # Salva relat√≥rio
    df.to_sql('relatorio_vendas_periodo', conn, schema='reports',
              if_exists='replace', index=False)
    
    conn.close()
    return df
'''
    
    with open(f"{exemplo_dir}/utils_dados.py", 'w') as f:
        f.write(script_util)
    
    print(f"‚úÖ C√≥digos de exemplo criados em: {exemplo_dir}/")
    return exemplo_dir


def executar_exemplo_completo():
    """Executa exemplo completo do BW_AUTOMATE"""
    
    print("\nüöÄ BW_AUTOMATE - EXEMPLO DE USO COMPLETO")
    print("="*50)
    
    # 1. Cria arquivos de exemplo
    print("\nüìÅ 1. Criando arquivos de exemplo...")
    tabelas_xlsx = criar_exemplo_tabelas_xlsx()
    codigo_dir = criar_codigo_python_exemplo()
    
    # 2. Configura BW_AUTOMATE
    print("\n‚öôÔ∏è 2. Configurando BW_AUTOMATE...")
    config_exemplo = {
        "analysis_settings": {
            "fuzzy_match_threshold": 75,
            "include_temp_tables": True,
            "schemas_to_analyze": ["public", "staging", "reports", "logs", "audit"],
            "max_files_to_analyze": 100
        },
        "reporting": {
            "generate_executive_dashboard": True,
            "generate_technical_report": True,
            "generate_table_explorer": True,
            "export_to_powerbi": True
        },
        "logging": {
            "log_level": "INFO"
        }
    }
    
    # 3. Executa an√°lise
    print("\nüîç 3. Executando an√°lise...")
    try:
        bw_automate = BWAutomate()
        bw_automate.config.update(config_exemplo)
        
        # Simula execu√ß√£o (sem executar realmente para n√£o dar erro)
        print("   ‚Ä¢ Validando arquivos de entrada...")
        print("   ‚Ä¢ Carregando tabelas oficiais...")
        print("   ‚Ä¢ Analisando c√≥digos Python...")
        print("   ‚Ä¢ Executando mapeamento de tabelas...")
        print("   ‚Ä¢ Gerando relat√≥rios...")
        
        print("\n‚úÖ An√°lise simulada conclu√≠da com sucesso!")
        
        # Mostra o que seria gerado
        print("\nüìä Relat√≥rios que seriam gerados:")
        print("   ‚Ä¢ executive_dashboard_YYYYMMDD_HHMMSS.html")
        print("   ‚Ä¢ technical_report_YYYYMMDD_HHMMSS.html")
        print("   ‚Ä¢ table_explorer_YYYYMMDD_HHMMSS.html")
        print("   ‚Ä¢ powerbi_export_YYYYMMDD_HHMMSS.xlsx")
        print("   ‚Ä¢ table_mappings_YYYYMMDD_HHMMSS.csv")
        
    except Exception as e:
        print(f"‚ùå Erro durante an√°lise: {e}")
    
    # 4. Instru√ß√µes para uso real
    print("\nüìã 4. Para uso real, execute:")
    print(f"python run_analysis.py --source-dir {codigo_dir} --tables-xlsx {tabelas_xlsx}")
    
    # 5. Limpeza (opcional)
    resposta = input("\nüßπ Deseja limpar os arquivos de exemplo? (s/n): ")
    if resposta.lower() == 's':
        import shutil
        os.remove(tabelas_xlsx)
        shutil.rmtree(codigo_dir)
        print("‚úÖ Arquivos de exemplo removidos")
    else:
        print(f"üìÅ Arquivos mantidos: {tabelas_xlsx}, {codigo_dir}/")
    
    print("\nüéâ Exemplo conclu√≠do!")


if __name__ == "__main__":
    executar_exemplo_completo()